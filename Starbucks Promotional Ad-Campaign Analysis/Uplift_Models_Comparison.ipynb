{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ATUNBu1gFwcR"
   },
   "source": [
    "An advertising promotion is tested to see if it would bring more customers to purchase a specific product priced at $10. Since it costs the company 0.15 to send out each promotion, it would be best to limit that promotion only to those that are most receptive to the promotion. \n",
    "\n",
    "#### Optimization Strategy\n",
    "\n",
    "Task is to use the training data to understand what patterns in 'Features' to indicate that a promotion should be provided to a user. Specifically,  goal is to maximize the following metrics:\n",
    "\n",
    "* **Incremental Response Rate (IRR)** \n",
    "\n",
    "IRR depicts how many more customers purchased the product with the promotion, as compared to if they didn't receive the promotion. \n",
    "\n",
    "* **Net Incremental Revenue (NIR)**\n",
    "\n",
    "NIR depicts how much is made (or lost) by sending out the promotion. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 71
    },
    "colab_type": "code",
    "id": "AkBUw_zCFwcS",
    "outputId": "ca39999b-fcd9-4252-bc5d-84e721105e7f",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/externals/six.py:31: DeprecationWarning: The module is deprecated in version 0.21 and will be removed in version 0.23 since we've dropped support for Python 2.7. Please rely on the official version of six (https://pypi.org/project/six/).\n",
      "  \"(https://pypi.org/project/six/).\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "# load in packages\n",
    "from itertools import combinations\n",
    "\n",
    "#from test_results import valid_results, test_results, score\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy as sp\n",
    "import sklearn as sk\n",
    "import xgboost as xgb\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from statsmodels.stats.power import NormalIndPower\n",
    "from statsmodels.stats.proportion import proportion_effectsize\n",
    "from google.oauth2 import service_account #For GCP Account connection\n",
    "from google.cloud import bigquery\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sb\n",
    "%matplotlib inline\n",
    "\n",
    "#Setting Up Project ID\n",
    "project_id = \"dsmt-team5-finalproject\"\n",
    "#Setting up the credential file\n",
    "cred = service_account.Credentials.from_service_account_file('dsmt-team5-finalproject-4f1119faadf9.json')\n",
    "#Setting up a BigQuery Client:\n",
    "client = bigquery.Client(project=project_id, credentials=cred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 224
    },
    "colab_type": "code",
    "id": "dBkWg0woFwcW",
    "outputId": "d49406b0-812a-428f-e21d-dc6b8cc56e43"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>day_num</th>\n",
       "      <th>per_id</th>\n",
       "      <th>offer_id</th>\n",
       "      <th>daily_amt_spent</th>\n",
       "      <th>num_trans</th>\n",
       "      <th>amt_spent_per_trans</th>\n",
       "      <th>num_offers</th>\n",
       "      <th>cost</th>\n",
       "      <th>profit</th>\n",
       "      <th>has_profit</th>\n",
       "      <th>target</th>\n",
       "      <th>quadrant</th>\n",
       "      <th>age</th>\n",
       "      <th>became_member_on</th>\n",
       "      <th>gender</th>\n",
       "      <th>income</th>\n",
       "      <th>gender_F</th>\n",
       "      <th>gender_M</th>\n",
       "      <th>gender_O</th>\n",
       "      <th>difficulty</th>\n",
       "      <th>duration</th>\n",
       "      <th>reward</th>\n",
       "      <th>email</th>\n",
       "      <th>mobile</th>\n",
       "      <th>social</th>\n",
       "      <th>web</th>\n",
       "      <th>offer_type_bogo</th>\n",
       "      <th>offer_type_discount</th>\n",
       "      <th>offer_type_informational</th>\n",
       "      <th>offer_id_0</th>\n",
       "      <th>offer_id_1</th>\n",
       "      <th>offer_id_2</th>\n",
       "      <th>offer_id_3</th>\n",
       "      <th>offer_id_4</th>\n",
       "      <th>offer_id_5</th>\n",
       "      <th>offer_id_6</th>\n",
       "      <th>offer_id_7</th>\n",
       "      <th>offer_id_8</th>\n",
       "      <th>offer_id_9</th>\n",
       "      <th>offer_id_10</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>40</td>\n",
       "      <td>20180109</td>\n",
       "      <td>O</td>\n",
       "      <td>57000.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>96</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>40</td>\n",
       "      <td>20180109</td>\n",
       "      <td>O</td>\n",
       "      <td>57000.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>59</td>\n",
       "      <td>20160304</td>\n",
       "      <td>F</td>\n",
       "      <td>90000.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>26</td>\n",
       "      <td>20170621</td>\n",
       "      <td>F</td>\n",
       "      <td>73000.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>19</td>\n",
       "      <td>20160809</td>\n",
       "      <td>F</td>\n",
       "      <td>65000.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   day_num  per_id  offer_id  ...  offer_id_8  offer_id_9  offer_id_10\n",
       "0      0.0     1.0       3.0  ...           0           0            0\n",
       "1      0.0     1.0      10.0  ...           0           0            1\n",
       "2      0.0     2.0      10.0  ...           0           0            1\n",
       "3      0.0     4.0      10.0  ...           0           0            1\n",
       "4      0.0     5.0      10.0  ...           0           0            1\n",
       "\n",
       "[5 rows x 40 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load in the data\n",
    "daily_data_sql = \"\"\"SELECT * FROM `dsmt-team5-finalproject.tacobell.daily_data_rolling`\"\"\"\n",
    "daily_data = client.query(daily_data_sql).to_dataframe()\n",
    "daily_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 714
    },
    "colab_type": "code",
    "id": "nwJIcEkYFwcZ",
    "outputId": "e4411beb-b318-4b7c-f739-5a73d7697e45"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "day_num                     0.0\n",
       "per_id                      0.0\n",
       "offer_id                    0.0\n",
       "daily_amt_spent             0.0\n",
       "num_trans                   0.0\n",
       "amt_spent_per_trans         0.0\n",
       "num_offers                  0.0\n",
       "cost                        0.0\n",
       "profit                      0.0\n",
       "has_profit                  0.0\n",
       "target                      0.0\n",
       "quadrant                    0.0\n",
       "age                         0.0\n",
       "became_member_on            0.0\n",
       "gender                      0.0\n",
       "income                      0.0\n",
       "gender_F                    0.0\n",
       "gender_M                    0.0\n",
       "gender_O                    0.0\n",
       "difficulty                  0.0\n",
       "duration                    0.0\n",
       "reward                      0.0\n",
       "email                       0.0\n",
       "mobile                      0.0\n",
       "social                      0.0\n",
       "web                         0.0\n",
       "offer_type_bogo             0.0\n",
       "offer_type_discount         0.0\n",
       "offer_type_informational    0.0\n",
       "offer_id_0                  0.0\n",
       "offer_id_1                  0.0\n",
       "offer_id_2                  0.0\n",
       "offer_id_3                  0.0\n",
       "offer_id_4                  0.0\n",
       "offer_id_5                  0.0\n",
       "offer_id_6                  0.0\n",
       "offer_id_7                  0.0\n",
       "offer_id_8                  0.0\n",
       "offer_id_9                  0.0\n",
       "offer_id_10                 0.0\n",
       "dtype: float64"
      ]
     },
     "execution_count": 3,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check number of missing values per column\n",
    "daily_data.isnull().mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Bs3vudeDHMTR"
   },
   "outputs": [],
   "source": [
    "def generate_offer_daily_data(offer_name, daily_data, start_day=0,\\\n",
    "                                end_day=29):\n",
    "\n",
    "       # Generate the subset of the original daily data that is relevant to \n",
    "       # the current offer.\n",
    "\n",
    "    for day_num in range(start_day,end_day+1):\n",
    "        # get the current day's data FOR ALL THE DAYS\n",
    "        day_subset = daily_data[daily_data['day_num']==day_num]\n",
    "        day_subset = day_subset[(day_subset[offer_name]==1) |\\\n",
    "                                    (day_subset['offer_id_10']==1)]\n",
    "        \n",
    "        # get individuals who received the offer DURING THE PARTICULAR 1 DAY\n",
    "        day_offer_indiv =\\\n",
    "        day_subset[day_subset[offer_name]==1].per_id.unique()           #unique per_id who received the offer 0\n",
    "        if day_num == start_day:\n",
    "            new_daily_data =\\\n",
    "            day_subset[day_subset['per_id'].isin(day_offer_indiv)]      # new_daily_data = day_subset data that contains the per_id who received the offer on day 0\n",
    "        else:\n",
    "            new_day_data =\\\n",
    "            day_subset[day_subset['per_id'].isin(day_offer_indiv)]\n",
    "            new_daily_data =\\\n",
    "            pd.concat([new_daily_data, new_day_data], axis=0)\n",
    "    new_daily_data.reset_index(inplace=True)\n",
    "    return new_daily_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "I6nrZNA8Fwcc"
   },
   "outputs": [],
   "source": [
    "train_data = generate_offer_daily_data('offer_id_0', daily_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1OzyKn7oFwce"
   },
   "outputs": [],
   "source": [
    "features = ['day_num', 'per_id', 'age', 'became_member_on', 'income', 'gender_F', 'gender_M','gender_O']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "colab_type": "code",
    "id": "grhlhVgfFwci",
    "outputId": "336fce0c-c436-4402-b3c5-02625e9fbf01"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    12744\n",
       "1     2830\n",
       "Name: target, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data['target'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qq3Cwq8FFwc5"
   },
   "outputs": [],
   "source": [
    "# testing baseline model, where we send promotions to everyone\n",
    "\n",
    "def promotion_strategy(df):\n",
    "    \n",
    "    test = df\n",
    "    \n",
    "    promotion = []\n",
    "    \n",
    "    num_test_points = test.shape[0]\n",
    "    \n",
    "    for i in range(num_test_points):\n",
    "        promotion.append('Yes')\n",
    "        \n",
    "    promotion = np.array(promotion)\n",
    "    \n",
    "    return promotion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Jql0wdICIPeZ"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def score(df, promo_pred_col = 'offer_id',promo_pred_col_2 = 'quadrant'):\n",
    "    n_treat       = df.loc[df[promo_pred_col] != 10 ,:].shape[0]\n",
    "    n_control     = df.loc[df[promo_pred_col] == 10 ,:].shape[0]\n",
    "   \n",
    "    n_treat_purch = df.loc[df[promo_pred_col_2] == 0 ].shape[0]\n",
    "    \n",
    "   \n",
    "    n_ctrl_purch  = df.loc[df[promo_pred_col_2] == 1 ].shape[0]\n",
    "    \n",
    "    irr = n_treat_purch / n_treat - n_ctrl_purch / n_control\n",
    "    nir = 10 * n_treat_purch - 0.15 * n_treat - 10 * n_ctrl_purch\n",
    "    return (irr, nir)\n",
    "  \n",
    "    \n",
    "\n",
    "# added this function to test our irr and nlr on the validation set\n",
    "def valid_results(promotion_strategy, valid_data):\n",
    "    df = valid_data[['day_num', 'per_id','age','became_member_on', 'income', 'gender_F', 'gender_M','gender_O']]\n",
    "                    \n",
    "    promos = promotion_strategy(df)\n",
    "    score_df = valid_data.iloc[np.where(promos == 'Yes')]    \n",
    "    irr, nir = score(score_df)\n",
    "   \n",
    "    \n",
    "    print('Irr with this strategy is {:0.4f}.'.format(irr))\n",
    "    print()\n",
    "   \n",
    "    print('Nir with this strategy is {:0.2f}.'.format(nir))\n",
    "    print()\n",
    "    \n",
    "    return irr, nir\n",
    "   \n",
    "def test_results(promotion_strategy):\n",
    "    test_data_sql = \"\"\"SELECT * FROM `dsmt-team5-finalproject.tacobell.rr_test_case`\"\"\"\n",
    "    test_data = client.query(test_data_sql).to_dataframe()\n",
    "    df = test_data[['day_num', 'per_id','age','became_member_on', 'income', 'gender_F', 'gender_M','gender_O']]\n",
    "    promos = promotion_strategy(df)\n",
    "    score_df = test_data.iloc[np.where(promos == 'Yes')]    \n",
    "    irr, nir = score(score_df)\n",
    "    \n",
    "    print('Irr with this strategy is {:0.4f}.'.format(irr))\n",
    "    print()\n",
    "    print('Nir with this strategy is {:0.2f}.'.format(nir))\n",
    "    \n",
    "    \n",
    "    return irr, nir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "hNgTZQrt_Dj8"
   },
   "outputs": [],
   "source": [
    "# This will test the baseline strategy\n",
    "\n",
    "#test_results(promotion_strategy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "azRAazhuFwdT"
   },
   "source": [
    "If we were to send everyone a promotion, this will be the baseline model. Hence, sending everyone a promotion is going to lose the company a lot of money."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "r1eVLh8u_C5t"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ts1s6Ht1FwdT"
   },
   "source": [
    "## Model 1: Predict only for individuals who received promotions and purchased\n",
    "\n",
    "In this approach, we will assign labels of 1 to those who received the promotions and made purchases, and labels of 0 to everyone else. In other words, we want the model to find the individuals who are likely to purchase only after they received a promotion. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 224
    },
    "colab_type": "code",
    "id": "bdGQ3o4xFwdZ",
    "outputId": "7b335271-bee3-432d-9f20-64e3d989f437"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>day_num</th>\n",
       "      <th>per_id</th>\n",
       "      <th>offer_id</th>\n",
       "      <th>daily_amt_spent</th>\n",
       "      <th>num_trans</th>\n",
       "      <th>amt_spent_per_trans</th>\n",
       "      <th>num_offers</th>\n",
       "      <th>cost</th>\n",
       "      <th>profit</th>\n",
       "      <th>has_profit</th>\n",
       "      <th>target</th>\n",
       "      <th>quadrant</th>\n",
       "      <th>age</th>\n",
       "      <th>became_member_on</th>\n",
       "      <th>gender</th>\n",
       "      <th>income</th>\n",
       "      <th>gender_F</th>\n",
       "      <th>gender_M</th>\n",
       "      <th>gender_O</th>\n",
       "      <th>difficulty</th>\n",
       "      <th>duration</th>\n",
       "      <th>reward</th>\n",
       "      <th>email</th>\n",
       "      <th>mobile</th>\n",
       "      <th>social</th>\n",
       "      <th>web</th>\n",
       "      <th>offer_type_bogo</th>\n",
       "      <th>offer_type_discount</th>\n",
       "      <th>offer_type_informational</th>\n",
       "      <th>offer_id_0</th>\n",
       "      <th>offer_id_1</th>\n",
       "      <th>offer_id_2</th>\n",
       "      <th>offer_id_3</th>\n",
       "      <th>offer_id_4</th>\n",
       "      <th>offer_id_5</th>\n",
       "      <th>offer_id_6</th>\n",
       "      <th>offer_id_7</th>\n",
       "      <th>offer_id_8</th>\n",
       "      <th>offer_id_9</th>\n",
       "      <th>offer_id_10</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>112</td>\n",
       "      <td>0.0</td>\n",
       "      <td>93.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>49</td>\n",
       "      <td>20170126</td>\n",
       "      <td>M</td>\n",
       "      <td>73000.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>240</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>113</td>\n",
       "      <td>0.0</td>\n",
       "      <td>93.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>49</td>\n",
       "      <td>20170126</td>\n",
       "      <td>M</td>\n",
       "      <td>73000.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>114</td>\n",
       "      <td>0.0</td>\n",
       "      <td>94.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>44</td>\n",
       "      <td>20180312</td>\n",
       "      <td>F</td>\n",
       "      <td>76000.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>240</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>115</td>\n",
       "      <td>0.0</td>\n",
       "      <td>94.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>44</td>\n",
       "      <td>20180312</td>\n",
       "      <td>F</td>\n",
       "      <td>76000.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>166</td>\n",
       "      <td>0.0</td>\n",
       "      <td>134.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>62</td>\n",
       "      <td>20180629</td>\n",
       "      <td>F</td>\n",
       "      <td>40000.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>240</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index  day_num  per_id  ...  offer_id_8  offer_id_9  offer_id_10\n",
       "0    112      0.0    93.0  ...           0           0            0\n",
       "1    113      0.0    93.0  ...           0           0            1\n",
       "2    114      0.0    94.0  ...           0           0            0\n",
       "3    115      0.0    94.0  ...           0           0            1\n",
       "4    166      0.0   134.0  ...           0           0            0\n",
       "\n",
       "[5 rows x 41 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ZCe9PwbnFwdc"
   },
   "outputs": [],
   "source": [
    "# split data into train and valid\n",
    "train, valid = sk.model_selection.train_test_split(train_data, test_size=0.2,random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 102
    },
    "colab_type": "code",
    "id": "C8djPWW7KURh",
    "outputId": "c2bfd220-97b0-46cb-ee04-fdad70cab4f2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Irr with this strategy is 0.2300.\n",
      "\n",
      "Nir with this strategy is 3249.60.\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.230019741529449, 3249.6000000000004)"
      ]
     },
     "execution_count": 15,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This will test your results, for baseline strategy\n",
    "# test irr and nlr on our validation set\n",
    "valid_results(promotion_strategy, valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5R8aCUYFFwde"
   },
   "outputs": [],
   "source": [
    "# generate features and labels\n",
    "Y_train = train['target']\n",
    "X_train = train[features]\n",
    "\n",
    "Y_valid = valid['target']\n",
    "X_valid = valid[features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "colab_type": "code",
    "id": "Xz1kbS3lFwdr",
    "outputId": "a368870d-6dc0-46fc-ac62-dcd8164e5ac2"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    10172\n",
       "1     2287\n",
       "Name: target, dtype: int64"
      ]
     },
     "execution_count": 17,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_train.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "uUMbQgzsFwdu"
   },
   "outputs": [],
   "source": [
    "# up sample only the train dataset with SMOTE\n",
    "sm = SMOTE(random_state=42, ratio = 1.0)\n",
    "X_train_upsamp, Y_train_upsamp = sm.fit_sample(X_train, Y_train)\n",
    "    \n",
    "X_train_upsamp = pd.DataFrame(X_train_upsamp, columns=features)\n",
    "\n",
    "Y_train_upsamp = pd.Series(Y_train_upsamp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "9j8oftrqFwdw",
    "outputId": "70be29a2-8aed-44ea-8662-3a2fdde32008"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\tvalidation_0-auc:0.843711\tvalidation_1-auc:0.719193\n",
      "Multiple eval metrics have been passed: 'validation_1-auc' will be used for early stopping.\n",
      "\n",
      "Will train until validation_1-auc hasn't improved in 30 rounds.\n",
      "[1]\tvalidation_0-auc:0.844779\tvalidation_1-auc:0.730671\n",
      "[2]\tvalidation_0-auc:0.932221\tvalidation_1-auc:0.791583\n",
      "[3]\tvalidation_0-auc:0.925724\tvalidation_1-auc:0.789821\n",
      "[4]\tvalidation_0-auc:0.93245\tvalidation_1-auc:0.792745\n",
      "[5]\tvalidation_0-auc:0.939509\tvalidation_1-auc:0.793682\n",
      "[6]\tvalidation_0-auc:0.937903\tvalidation_1-auc:0.791756\n",
      "[7]\tvalidation_0-auc:0.943157\tvalidation_1-auc:0.794192\n",
      "[8]\tvalidation_0-auc:0.941479\tvalidation_1-auc:0.792058\n",
      "[9]\tvalidation_0-auc:0.941395\tvalidation_1-auc:0.792035\n",
      "[10]\tvalidation_0-auc:0.945044\tvalidation_1-auc:0.793527\n",
      "[11]\tvalidation_0-auc:0.948979\tvalidation_1-auc:0.794559\n",
      "[12]\tvalidation_0-auc:0.947957\tvalidation_1-auc:0.793674\n",
      "[13]\tvalidation_0-auc:0.950512\tvalidation_1-auc:0.794982\n",
      "[14]\tvalidation_0-auc:0.948909\tvalidation_1-auc:0.79382\n",
      "[15]\tvalidation_0-auc:0.950654\tvalidation_1-auc:0.794714\n",
      "[16]\tvalidation_0-auc:0.951331\tvalidation_1-auc:0.794298\n",
      "[17]\tvalidation_0-auc:0.953133\tvalidation_1-auc:0.796396\n",
      "[18]\tvalidation_0-auc:0.953195\tvalidation_1-auc:0.795369\n",
      "[19]\tvalidation_0-auc:0.954275\tvalidation_1-auc:0.795722\n",
      "[20]\tvalidation_0-auc:0.954282\tvalidation_1-auc:0.795376\n",
      "[21]\tvalidation_0-auc:0.955531\tvalidation_1-auc:0.795232\n",
      "[22]\tvalidation_0-auc:0.956686\tvalidation_1-auc:0.797047\n",
      "[23]\tvalidation_0-auc:0.957297\tvalidation_1-auc:0.797456\n",
      "[24]\tvalidation_0-auc:0.958269\tvalidation_1-auc:0.797157\n",
      "[25]\tvalidation_0-auc:0.959417\tvalidation_1-auc:0.797894\n",
      "[26]\tvalidation_0-auc:0.960162\tvalidation_1-auc:0.798208\n",
      "[27]\tvalidation_0-auc:0.960772\tvalidation_1-auc:0.799129\n",
      "[28]\tvalidation_0-auc:0.961162\tvalidation_1-auc:0.800094\n",
      "[29]\tvalidation_0-auc:0.962114\tvalidation_1-auc:0.801183\n",
      "[30]\tvalidation_0-auc:0.962199\tvalidation_1-auc:0.799512\n",
      "[31]\tvalidation_0-auc:0.962738\tvalidation_1-auc:0.800818\n",
      "[32]\tvalidation_0-auc:0.962937\tvalidation_1-auc:0.800167\n",
      "[33]\tvalidation_0-auc:0.963328\tvalidation_1-auc:0.800577\n",
      "[34]\tvalidation_0-auc:0.963556\tvalidation_1-auc:0.799513\n",
      "[35]\tvalidation_0-auc:0.963869\tvalidation_1-auc:0.799799\n",
      "[36]\tvalidation_0-auc:0.963919\tvalidation_1-auc:0.799403\n",
      "[37]\tvalidation_0-auc:0.964302\tvalidation_1-auc:0.800139\n",
      "[38]\tvalidation_0-auc:0.964376\tvalidation_1-auc:0.800621\n",
      "[39]\tvalidation_0-auc:0.965005\tvalidation_1-auc:0.800182\n",
      "[40]\tvalidation_0-auc:0.965504\tvalidation_1-auc:0.800089\n",
      "[41]\tvalidation_0-auc:0.965848\tvalidation_1-auc:0.800492\n",
      "[42]\tvalidation_0-auc:0.966086\tvalidation_1-auc:0.799788\n",
      "[43]\tvalidation_0-auc:0.966048\tvalidation_1-auc:0.799737\n",
      "[44]\tvalidation_0-auc:0.966427\tvalidation_1-auc:0.798909\n",
      "[45]\tvalidation_0-auc:0.966696\tvalidation_1-auc:0.797697\n",
      "[46]\tvalidation_0-auc:0.966779\tvalidation_1-auc:0.798342\n",
      "[47]\tvalidation_0-auc:0.966913\tvalidation_1-auc:0.798348\n",
      "[48]\tvalidation_0-auc:0.966929\tvalidation_1-auc:0.798968\n",
      "[49]\tvalidation_0-auc:0.967028\tvalidation_1-auc:0.798458\n",
      "[50]\tvalidation_0-auc:0.967297\tvalidation_1-auc:0.798772\n",
      "[51]\tvalidation_0-auc:0.967331\tvalidation_1-auc:0.798753\n",
      "[52]\tvalidation_0-auc:0.967561\tvalidation_1-auc:0.797991\n",
      "[53]\tvalidation_0-auc:0.967584\tvalidation_1-auc:0.797931\n",
      "[54]\tvalidation_0-auc:0.967731\tvalidation_1-auc:0.79788\n",
      "[55]\tvalidation_0-auc:0.967947\tvalidation_1-auc:0.797957\n",
      "[56]\tvalidation_0-auc:0.96796\tvalidation_1-auc:0.797769\n",
      "[57]\tvalidation_0-auc:0.968027\tvalidation_1-auc:0.797689\n",
      "[58]\tvalidation_0-auc:0.968215\tvalidation_1-auc:0.796854\n",
      "[59]\tvalidation_0-auc:0.968422\tvalidation_1-auc:0.79631\n",
      "Stopping. Best iteration:\n",
      "[29]\tvalidation_0-auc:0.962114\tvalidation_1-auc:0.801183\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "              colsample_bynode=1, colsample_bytree=1, gamma=0.1,\n",
       "              learning_rate=0.1, max_delta_step=0, max_depth=7,\n",
       "              min_child_weight=5, missing=None, n_estimators=100, n_jobs=1,\n",
       "              nthread=None, objective='binary:logistic', random_state=0,\n",
       "              reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=42,\n",
       "              silent=True, subsample=1, verbosity=1)"
      ]
     },
     "execution_count": 19,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Train an xgboost model\n",
    "eval_set = [(X_train_upsamp, Y_train_upsamp), (X_valid, Y_valid)]\n",
    "model = xgb.XGBClassifier(learning_rate = 0.1,\\\n",
    "                          max_depth = 7,\\\n",
    "                          min_child_weight = 5,\\\n",
    "                          objective = 'binary:logistic',\\\n",
    "                          seed = 42,\\\n",
    "                          gamma = 0.1,\\\n",
    "                          silent = True)\n",
    "model.fit(X_train_upsamp, Y_train_upsamp, eval_set=eval_set,\\\n",
    "          eval_metric=\"auc\", verbose=True, early_stopping_rounds=30)\n",
    "\n",
    "#import pickle\n",
    "# save model to file\n",
    "#pickle.dump(model, open(\"uplift.pickle.dat\", \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "F2FXvRWLuEES"
   },
   "outputs": [],
   "source": [
    "# load model from file\n",
    "#loaded_model = pickle.load(open(\"uplift.pickle.dat\", \"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "BDO7cX8NFwdz",
    "outputId": "51ed4ebc-8feb-49a6-edae-26f79994d000"
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAArwAAAQPCAYAAADyNDiiAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nghcAgKEJXgAAhiZ4AQAYmuAFAGBo/x8mqI0GFlcT8QAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 720x1296 with 1 Axes>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# check which features are important\n",
    "\n",
    "from xgboost import plot_importance\n",
    "from matplotlib import pyplot\n",
    "\n",
    "fig, ax = pyplot.subplots(figsize=(10, 18));\n",
    "xgb.plot_importance(model, ax=ax);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "vixC_D53Fwd1",
    "outputId": "84336414-d910-4724-e3e8-d02695fc6eda"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2147,  425],\n",
       "       [ 156,  387]])"
      ]
     },
     "execution_count": 22,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# confusion matrix\n",
    "valid_pred = model.predict(X_valid, ntree_limit=model.best_ntree_limit)\n",
    "cm = sk.metrics.confusion_matrix\n",
    "cm(Y_valid, valid_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "QIJjxrryFwd-"
   },
   "outputs": [],
   "source": [
    "def promotion_strategy(df):\n",
    "\n",
    "    test = df\n",
    "    \n",
    "    preds = model.predict(test, ntree_limit=model.best_ntree_limit)\n",
    "\n",
    "    promotion = []\n",
    "    for pred in preds:\n",
    "        if pred == 1:\n",
    "            promotion.append('Yes')\n",
    "        else:\n",
    "            promotion.append('No')\n",
    "    promotion = np.array(promotion)\n",
    "    return promotion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 102
    },
    "colab_type": "code",
    "id": "PKsygvWOFweB",
    "outputId": "84f88f11-df22-469a-d2c8-aa6b56d08ab0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Irr with this strategy is 0.9200.\n",
      "\n",
      "Nir with this strategy is 3471.95.\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.92, 3471.95)"
      ]
     },
     "execution_count": 24,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test irr and nlr on our validation set\n",
    "valid_results(promotion_strategy, valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "WRIWzKquC8Cp"
   },
   "outputs": [],
   "source": [
    "# This will test results, and provide back how well your promotion_strategy will work in practice\n",
    "\n",
    "#test_results(promotion_strategy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "hrERVVhBFweE"
   },
   "source": [
    "## Model 2: Using Two Models\n",
    "\n",
    "In this approach, we will train two models. \n",
    "One model will be trained on the treatment group (those who received the promotion) and we will refer to this model as the treatment model. \n",
    "Another model will be trained on the control group (those who did not received the promotion), and we will refer to this as the control model. \n",
    "The target of both models will be whether the individual made the purchase or not. \n",
    "The treatment model will predict the probability that individual will make a purchase if he or she received the promotion, while the control model will predict the probability that individual will make a purchase if he or she did not receive the promotion. \n",
    "Ideally the difference in the probabilities, which we will call the lift will tell us the probability that sending a promotion to an individual will increase his or her willingness to make a purhcase vs not sending a promotion. We can then send promotions to individuals with lift values higher than a pre-defined cutoff percentile. For example, we can send promotions to individuals in the top 3 deciles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "OObVE_0bFweH"
   },
   "outputs": [],
   "source": [
    "# split data into train and valid\n",
    "train, valid = sk.model_selection.train_test_split(train_data, test_size=0.2,random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4TthvhSuFweI"
   },
   "outputs": [],
   "source": [
    "features = ['day_num', 'per_id', 'age', 'became_member_on', 'income', 'gender_F', 'gender_M','gender_O']\n",
    "\n",
    "# Generate validation data one for control group, another for treatment group\n",
    "valid_control = valid[valid['offer_id']==10]\n",
    "Y_valid_control = valid_control['has_profit']\n",
    "X_valid_control = valid_control[features]\n",
    "\n",
    "valid_exper = valid[valid['offer_id']!=10]\n",
    "Y_valid_exper = valid_exper['has_profit']\n",
    "X_valid_exper = valid_exper[features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "WOVKgpHjFweK"
   },
   "outputs": [],
   "source": [
    "# generate training data\n",
    "train_control = train[train['offer_id']==10]\n",
    "Y_train_control = train_control['has_profit']\n",
    "X_train_control = train_control[features]\n",
    "\n",
    "train_exper = train[train['offer_id']!=10]\n",
    "Y_train_exper = train_exper['has_profit']\n",
    "X_train_exper = train_exper[features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "e2gG8OQ6FweN"
   },
   "outputs": [],
   "source": [
    "# up-sample training data with SMOTE\n",
    "sm = SMOTE(random_state=42, ratio = 1.0)\n",
    "\n",
    "# up-sample control group\n",
    "X_train_control_upsamp, Y_train_control_upsamp = sm.fit_sample(X_train_control, Y_train_control)\n",
    "X_train_control_upsamp = pd.DataFrame(X_train_control_upsamp, columns=features)\n",
    "Y_train_control_upsamp = pd.Series(Y_train_control_upsamp)\n",
    "\n",
    "# up-sample treatment group\n",
    "X_train_exper_upsamp, Y_train_exper_upsamp = sm.fit_sample(X_train_exper, Y_train_exper)    \n",
    "X_train_exper_upsamp = pd.DataFrame(X_train_exper_upsamp, columns=features)\n",
    "Y_train_exper_upsamp = pd.Series(Y_train_exper_upsamp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 833
    },
    "colab_type": "code",
    "id": "_B9SKvUcFweP",
    "outputId": "435652c8-55e3-4d7e-e719-38cb61bcc2d6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\tvalidation_0-auc:0.861602\tvalidation_1-auc:0.534095\n",
      "Multiple eval metrics have been passed: 'validation_1-auc' will be used for early stopping.\n",
      "\n",
      "Will train until validation_1-auc hasn't improved in 30 rounds.\n",
      "[1]\tvalidation_0-auc:0.885753\tvalidation_1-auc:0.534178\n",
      "[2]\tvalidation_0-auc:0.887618\tvalidation_1-auc:0.539351\n",
      "[3]\tvalidation_0-auc:0.89351\tvalidation_1-auc:0.543364\n",
      "[4]\tvalidation_0-auc:0.89371\tvalidation_1-auc:0.545431\n",
      "[5]\tvalidation_0-auc:0.904315\tvalidation_1-auc:0.539903\n",
      "[6]\tvalidation_0-auc:0.908736\tvalidation_1-auc:0.542078\n",
      "[7]\tvalidation_0-auc:0.911288\tvalidation_1-auc:0.539438\n",
      "[8]\tvalidation_0-auc:0.915773\tvalidation_1-auc:0.537326\n",
      "[9]\tvalidation_0-auc:0.916858\tvalidation_1-auc:0.536157\n",
      "[10]\tvalidation_0-auc:0.918738\tvalidation_1-auc:0.533743\n",
      "[11]\tvalidation_0-auc:0.924546\tvalidation_1-auc:0.532779\n",
      "[12]\tvalidation_0-auc:0.927831\tvalidation_1-auc:0.532713\n",
      "[13]\tvalidation_0-auc:0.928186\tvalidation_1-auc:0.53589\n",
      "[14]\tvalidation_0-auc:0.930783\tvalidation_1-auc:0.536387\n",
      "[15]\tvalidation_0-auc:0.932864\tvalidation_1-auc:0.53426\n",
      "[16]\tvalidation_0-auc:0.934756\tvalidation_1-auc:0.537124\n",
      "[17]\tvalidation_0-auc:0.936247\tvalidation_1-auc:0.535857\n",
      "[18]\tvalidation_0-auc:0.937478\tvalidation_1-auc:0.534556\n",
      "[19]\tvalidation_0-auc:0.937914\tvalidation_1-auc:0.532522\n",
      "[20]\tvalidation_0-auc:0.938818\tvalidation_1-auc:0.532172\n",
      "[21]\tvalidation_0-auc:0.93988\tvalidation_1-auc:0.53255\n",
      "[22]\tvalidation_0-auc:0.940468\tvalidation_1-auc:0.53192\n",
      "[23]\tvalidation_0-auc:0.943803\tvalidation_1-auc:0.527927\n",
      "[24]\tvalidation_0-auc:0.945984\tvalidation_1-auc:0.529722\n",
      "[25]\tvalidation_0-auc:0.948906\tvalidation_1-auc:0.527822\n",
      "[26]\tvalidation_0-auc:0.949433\tvalidation_1-auc:0.528363\n",
      "[27]\tvalidation_0-auc:0.949821\tvalidation_1-auc:0.527403\n",
      "[28]\tvalidation_0-auc:0.950832\tvalidation_1-auc:0.528772\n",
      "[29]\tvalidation_0-auc:0.95105\tvalidation_1-auc:0.530184\n",
      "[30]\tvalidation_0-auc:0.951617\tvalidation_1-auc:0.53086\n",
      "[31]\tvalidation_0-auc:0.951884\tvalidation_1-auc:0.531331\n",
      "[32]\tvalidation_0-auc:0.952678\tvalidation_1-auc:0.530725\n",
      "[33]\tvalidation_0-auc:0.952901\tvalidation_1-auc:0.532099\n",
      "[34]\tvalidation_0-auc:0.953076\tvalidation_1-auc:0.532481\n",
      "Stopping. Best iteration:\n",
      "[4]\tvalidation_0-auc:0.89371\tvalidation_1-auc:0.545431\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "              colsample_bynode=1, colsample_bytree=1, gamma=1,\n",
       "              learning_rate=0.1, max_delta_step=0, max_depth=7,\n",
       "              min_child_weight=5, missing=None, n_estimators=100, n_jobs=1,\n",
       "              nthread=None, objective='binary:logistic', random_state=0,\n",
       "              reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=42,\n",
       "              silent=True, subsample=1, verbosity=1)"
      ]
     },
     "execution_count": 32,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train control model\n",
    "eval_set = [(X_train_control_upsamp, Y_train_control_upsamp), (X_valid_control, Y_valid_control)]\n",
    "model_control = xgb.XGBClassifier(learning_rate = 0.1,\\\n",
    "                                  max_depth = 7,\\\n",
    "                                  min_child_weight = 5,\\\n",
    "                                  objective = 'binary:logistic',\\\n",
    "                                  seed = 42,\\\n",
    "                                  gamma = 1,\\\n",
    "                                  #colsample_bytree = 0.1,\\\n",
    "                                  silent = True)\n",
    "model_control.fit(X_train_control_upsamp, Y_train_control_upsamp, eval_set=eval_set,\\\n",
    "                    eval_metric=\"auc\", verbose=True, early_stopping_rounds=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "nicZdlCjFweR",
    "outputId": "cf295f77-9148-49e7-d0b4-3850cccc1d12"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\tvalidation_0-auc:0.860512\tvalidation_1-auc:0.822347\n",
      "Multiple eval metrics have been passed: 'validation_1-auc' will be used for early stopping.\n",
      "\n",
      "Will train until validation_1-auc hasn't improved in 30 rounds.\n",
      "[1]\tvalidation_0-auc:0.942944\tvalidation_1-auc:0.884253\n",
      "[2]\tvalidation_0-auc:0.946975\tvalidation_1-auc:0.887605\n",
      "[3]\tvalidation_0-auc:0.944969\tvalidation_1-auc:0.885654\n",
      "[4]\tvalidation_0-auc:0.948912\tvalidation_1-auc:0.886489\n",
      "[5]\tvalidation_0-auc:0.948923\tvalidation_1-auc:0.888753\n",
      "[6]\tvalidation_0-auc:0.949647\tvalidation_1-auc:0.888214\n",
      "[7]\tvalidation_0-auc:0.950388\tvalidation_1-auc:0.890281\n",
      "[8]\tvalidation_0-auc:0.952809\tvalidation_1-auc:0.88892\n",
      "[9]\tvalidation_0-auc:0.953169\tvalidation_1-auc:0.889753\n",
      "[10]\tvalidation_0-auc:0.955901\tvalidation_1-auc:0.892462\n",
      "[11]\tvalidation_0-auc:0.956347\tvalidation_1-auc:0.893301\n",
      "[12]\tvalidation_0-auc:0.957941\tvalidation_1-auc:0.893658\n",
      "[13]\tvalidation_0-auc:0.958667\tvalidation_1-auc:0.893347\n",
      "[14]\tvalidation_0-auc:0.958474\tvalidation_1-auc:0.89253\n",
      "[15]\tvalidation_0-auc:0.959546\tvalidation_1-auc:0.892947\n",
      "[16]\tvalidation_0-auc:0.959784\tvalidation_1-auc:0.892791\n",
      "[17]\tvalidation_0-auc:0.959557\tvalidation_1-auc:0.893965\n",
      "[18]\tvalidation_0-auc:0.960134\tvalidation_1-auc:0.894222\n",
      "[19]\tvalidation_0-auc:0.960698\tvalidation_1-auc:0.893164\n",
      "[20]\tvalidation_0-auc:0.960722\tvalidation_1-auc:0.893157\n",
      "[21]\tvalidation_0-auc:0.961091\tvalidation_1-auc:0.893508\n",
      "[22]\tvalidation_0-auc:0.96177\tvalidation_1-auc:0.893604\n",
      "[23]\tvalidation_0-auc:0.962457\tvalidation_1-auc:0.893612\n",
      "[24]\tvalidation_0-auc:0.962454\tvalidation_1-auc:0.892711\n",
      "[25]\tvalidation_0-auc:0.962518\tvalidation_1-auc:0.893907\n",
      "[26]\tvalidation_0-auc:0.962787\tvalidation_1-auc:0.894078\n",
      "[27]\tvalidation_0-auc:0.965338\tvalidation_1-auc:0.899253\n",
      "[28]\tvalidation_0-auc:0.965925\tvalidation_1-auc:0.899507\n",
      "[29]\tvalidation_0-auc:0.966367\tvalidation_1-auc:0.898585\n",
      "[30]\tvalidation_0-auc:0.968484\tvalidation_1-auc:0.902774\n",
      "[31]\tvalidation_0-auc:0.968516\tvalidation_1-auc:0.902129\n",
      "[32]\tvalidation_0-auc:0.969808\tvalidation_1-auc:0.904685\n",
      "[33]\tvalidation_0-auc:0.970152\tvalidation_1-auc:0.90462\n",
      "[34]\tvalidation_0-auc:0.970817\tvalidation_1-auc:0.904646\n",
      "[35]\tvalidation_0-auc:0.970974\tvalidation_1-auc:0.904499\n",
      "[36]\tvalidation_0-auc:0.972231\tvalidation_1-auc:0.907223\n",
      "[37]\tvalidation_0-auc:0.972561\tvalidation_1-auc:0.906602\n",
      "[38]\tvalidation_0-auc:0.972596\tvalidation_1-auc:0.906151\n",
      "[39]\tvalidation_0-auc:0.973574\tvalidation_1-auc:0.908049\n",
      "[40]\tvalidation_0-auc:0.974093\tvalidation_1-auc:0.908624\n",
      "[41]\tvalidation_0-auc:0.973955\tvalidation_1-auc:0.908846\n",
      "[42]\tvalidation_0-auc:0.974223\tvalidation_1-auc:0.908821\n",
      "[43]\tvalidation_0-auc:0.974278\tvalidation_1-auc:0.908737\n",
      "[44]\tvalidation_0-auc:0.975105\tvalidation_1-auc:0.910073\n",
      "[45]\tvalidation_0-auc:0.975205\tvalidation_1-auc:0.909819\n",
      "[46]\tvalidation_0-auc:0.975904\tvalidation_1-auc:0.911227\n",
      "[47]\tvalidation_0-auc:0.976182\tvalidation_1-auc:0.91198\n",
      "[48]\tvalidation_0-auc:0.976215\tvalidation_1-auc:0.912123\n",
      "[49]\tvalidation_0-auc:0.976429\tvalidation_1-auc:0.912264\n",
      "[50]\tvalidation_0-auc:0.97655\tvalidation_1-auc:0.911867\n",
      "[51]\tvalidation_0-auc:0.976963\tvalidation_1-auc:0.912628\n",
      "[52]\tvalidation_0-auc:0.976996\tvalidation_1-auc:0.912986\n",
      "[53]\tvalidation_0-auc:0.977405\tvalidation_1-auc:0.913675\n",
      "[54]\tvalidation_0-auc:0.977399\tvalidation_1-auc:0.913116\n",
      "[55]\tvalidation_0-auc:0.977547\tvalidation_1-auc:0.913231\n",
      "[56]\tvalidation_0-auc:0.977526\tvalidation_1-auc:0.913021\n",
      "[57]\tvalidation_0-auc:0.978284\tvalidation_1-auc:0.913626\n",
      "[58]\tvalidation_0-auc:0.978557\tvalidation_1-auc:0.913493\n",
      "[59]\tvalidation_0-auc:0.979422\tvalidation_1-auc:0.913773\n",
      "[60]\tvalidation_0-auc:0.979443\tvalidation_1-auc:0.913816\n",
      "[61]\tvalidation_0-auc:0.979733\tvalidation_1-auc:0.914037\n",
      "[62]\tvalidation_0-auc:0.979972\tvalidation_1-auc:0.913801\n",
      "[63]\tvalidation_0-auc:0.980913\tvalidation_1-auc:0.913714\n",
      "[64]\tvalidation_0-auc:0.98099\tvalidation_1-auc:0.913933\n",
      "[65]\tvalidation_0-auc:0.981262\tvalidation_1-auc:0.914111\n",
      "[66]\tvalidation_0-auc:0.981352\tvalidation_1-auc:0.91432\n",
      "[67]\tvalidation_0-auc:0.981997\tvalidation_1-auc:0.914898\n",
      "[68]\tvalidation_0-auc:0.982165\tvalidation_1-auc:0.914909\n",
      "[69]\tvalidation_0-auc:0.982316\tvalidation_1-auc:0.914278\n",
      "[70]\tvalidation_0-auc:0.982403\tvalidation_1-auc:0.914176\n",
      "[71]\tvalidation_0-auc:0.982784\tvalidation_1-auc:0.915032\n",
      "[72]\tvalidation_0-auc:0.98284\tvalidation_1-auc:0.915141\n",
      "[73]\tvalidation_0-auc:0.983037\tvalidation_1-auc:0.914668\n",
      "[74]\tvalidation_0-auc:0.983092\tvalidation_1-auc:0.915113\n",
      "[75]\tvalidation_0-auc:0.983368\tvalidation_1-auc:0.914862\n",
      "[76]\tvalidation_0-auc:0.983899\tvalidation_1-auc:0.915723\n",
      "[77]\tvalidation_0-auc:0.984312\tvalidation_1-auc:0.915078\n",
      "[78]\tvalidation_0-auc:0.985028\tvalidation_1-auc:0.915409\n",
      "[79]\tvalidation_0-auc:0.985041\tvalidation_1-auc:0.915568\n",
      "[80]\tvalidation_0-auc:0.985337\tvalidation_1-auc:0.915754\n",
      "[81]\tvalidation_0-auc:0.985513\tvalidation_1-auc:0.915822\n",
      "[82]\tvalidation_0-auc:0.985768\tvalidation_1-auc:0.915617\n",
      "[83]\tvalidation_0-auc:0.985911\tvalidation_1-auc:0.915559\n",
      "[84]\tvalidation_0-auc:0.985922\tvalidation_1-auc:0.915377\n",
      "[85]\tvalidation_0-auc:0.986012\tvalidation_1-auc:0.915071\n",
      "[86]\tvalidation_0-auc:0.986107\tvalidation_1-auc:0.915099\n",
      "[87]\tvalidation_0-auc:0.986126\tvalidation_1-auc:0.915414\n",
      "[88]\tvalidation_0-auc:0.986269\tvalidation_1-auc:0.915375\n",
      "[89]\tvalidation_0-auc:0.986439\tvalidation_1-auc:0.91563\n",
      "[90]\tvalidation_0-auc:0.98663\tvalidation_1-auc:0.915197\n",
      "[91]\tvalidation_0-auc:0.986726\tvalidation_1-auc:0.915249\n",
      "[92]\tvalidation_0-auc:0.986826\tvalidation_1-auc:0.915461\n",
      "[93]\tvalidation_0-auc:0.986833\tvalidation_1-auc:0.915676\n",
      "[94]\tvalidation_0-auc:0.986974\tvalidation_1-auc:0.915587\n",
      "[95]\tvalidation_0-auc:0.987109\tvalidation_1-auc:0.915407\n",
      "[96]\tvalidation_0-auc:0.987176\tvalidation_1-auc:0.915105\n",
      "[97]\tvalidation_0-auc:0.987248\tvalidation_1-auc:0.91481\n",
      "[98]\tvalidation_0-auc:0.987275\tvalidation_1-auc:0.915155\n",
      "[99]\tvalidation_0-auc:0.987492\tvalidation_1-auc:0.915565\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "              colsample_bynode=1, colsample_bytree=1, gamma=1,\n",
       "              learning_rate=0.1, max_delta_step=0, max_depth=7,\n",
       "              min_child_weight=5, missing=None, n_estimators=100, n_jobs=1,\n",
       "              nthread=None, objective='binary:logistic', random_state=0,\n",
       "              reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=42,\n",
       "              silent=True, subsample=1, verbosity=1)"
      ]
     },
     "execution_count": 33,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train treatment model\n",
    "eval_set = [(X_train_exper_upsamp, Y_train_exper_upsamp), (X_valid_exper, Y_valid_exper)]\n",
    "model_exper = xgb.XGBClassifier(learning_rate = 0.1,\\\n",
    "                                max_depth = 7,\\\n",
    "                                min_child_weight = 5,\\\n",
    "                                objective = 'binary:logistic',\\\n",
    "                                seed = 42,\\\n",
    "                                gamma = 1,\\\n",
    "                                #colsample_bytree = 0.1,\\\n",
    "                                silent = True)\n",
    "model_exper.fit(X_train_exper_upsamp, Y_train_exper_upsamp, eval_set=eval_set,\\\n",
    "                eval_metric=\"auc\", verbose=True, early_stopping_rounds=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "yjn3HK_fFweU"
   },
   "outputs": [],
   "source": [
    "# make predictions on the validation data sets for both models\n",
    "control_valid_pred = model_control.predict(X_valid_control, ntree_limit=model_control.best_ntree_limit)\n",
    "exper_valid_pred = model_exper.predict(X_valid_exper, ntree_limit=model_exper.best_ntree_limit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "vTnw03bZFwef",
    "outputId": "67fdc7b2-5a71-4f58-eaff-bcb559b1f011"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[992,   1],\n",
       "       [140, 403]])"
      ]
     },
     "execution_count": 35,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# confusion marix for thge validation set\n",
    "valid_pred = model.predict(X_valid, ntree_limit=model.best_ntree_limit)\n",
    "cm = sk.metrics.confusion_matrix(Y_valid_exper, exper_valid_pred)\n",
    "\n",
    "cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "SRTtrwoHFweh"
   },
   "outputs": [],
   "source": [
    "def promotion_strategy(df):\n",
    "\n",
    "    test = df\n",
    "    \n",
    "    pred_probs_contol = model_control.predict_proba(test, ntree_limit=model_control.best_ntree_limit)\n",
    "\n",
    "    pred_probs_exper = model_exper.predict_proba(test, ntree_limit=model_exper.best_ntree_limit)\n",
    "\n",
    "    # get difference in probabilities between experimental and cpntrol model for purchase = 1 label\n",
    "    lift = pred_probs_exper[:,1] - pred_probs_contol[:,1]\n",
    "    \n",
    "    promotion = []\n",
    "    \n",
    "    # Only send promotions to top 3 percentile of probabilities\n",
    "    cutoff_lift = np.percentile(lift, 97)\n",
    "    \n",
    "    for prob in lift:\n",
    "        if prob > 0:\n",
    "            if prob > cutoff_lift:\n",
    "                promotion.append('Yes')\n",
    "        else:\n",
    "            promotion.append('No')\n",
    "\n",
    "    promotion = np.array(promotion)\n",
    "    \n",
    "    return promotion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 102
    },
    "colab_type": "code",
    "id": "jzdONgCCFwen",
    "outputId": "00b04b07-0e6e-458c-c9ee-41f53950a67a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Irr with this strategy is 0.3821.\n",
      "\n",
      "Nir with this strategy is 182.65.\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.3820598006644518, 182.65)"
      ]
     },
     "execution_count": 37,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# find out irr and nlr on our validation set\n",
    "valid_results(promotion_strategy, valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "XvBcdsrnFwes"
   },
   "outputs": [],
   "source": [
    "# This will test your results, and provide you back some information \n",
    "# on how well your promotion_strategy will work in practice\n",
    "\n",
    "#test_results(promotion_strategy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "FdRYQ6ijFwev"
   },
   "source": [
    "## Model 3: Using Treatment Dummy Approach\n",
    "\n",
    "In this approach, a single model is used to model the data. This approach adds an additional indicator variable to track if an individual is in a treatment or control group during training. Any individuals who made purchases will be given a label of 1, irregradless of whether he or she is in the control or treatment group. \n",
    "\n",
    "To predict whether a new individual in a test set is likely to make a purhcase only after receiving a promotion, we can first calculate the probability that the individual will make a purchase if he or she is in the treatment group by setting the treatment indicator as 1. Next, we calculate the probability that the individual will make a purchase if he or she is in the control group by setting the treatment indicator as 0. The difference in the two probabilities will be the lift value, aka, how positively influenced the individual is as a result of the treatment (receiving promotion)\n",
    "\n",
    "We can opt to send promotions to individuals with prostive lift values. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 224
    },
    "colab_type": "code",
    "id": "Q6so0ru-Fwew",
    "outputId": "3625e348-c5c6-4ad6-acbf-3ae1e215f26d"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>day_num</th>\n",
       "      <th>per_id</th>\n",
       "      <th>offer_id</th>\n",
       "      <th>daily_amt_spent</th>\n",
       "      <th>num_trans</th>\n",
       "      <th>amt_spent_per_trans</th>\n",
       "      <th>num_offers</th>\n",
       "      <th>cost</th>\n",
       "      <th>profit</th>\n",
       "      <th>has_profit</th>\n",
       "      <th>target</th>\n",
       "      <th>quadrant</th>\n",
       "      <th>age</th>\n",
       "      <th>became_member_on</th>\n",
       "      <th>gender</th>\n",
       "      <th>income</th>\n",
       "      <th>gender_F</th>\n",
       "      <th>gender_M</th>\n",
       "      <th>gender_O</th>\n",
       "      <th>difficulty</th>\n",
       "      <th>duration</th>\n",
       "      <th>reward</th>\n",
       "      <th>email</th>\n",
       "      <th>mobile</th>\n",
       "      <th>social</th>\n",
       "      <th>web</th>\n",
       "      <th>offer_type_bogo</th>\n",
       "      <th>offer_type_discount</th>\n",
       "      <th>offer_type_informational</th>\n",
       "      <th>offer_id_0</th>\n",
       "      <th>offer_id_1</th>\n",
       "      <th>offer_id_2</th>\n",
       "      <th>offer_id_3</th>\n",
       "      <th>offer_id_4</th>\n",
       "      <th>offer_id_5</th>\n",
       "      <th>offer_id_6</th>\n",
       "      <th>offer_id_7</th>\n",
       "      <th>offer_id_8</th>\n",
       "      <th>offer_id_9</th>\n",
       "      <th>offer_id_10</th>\n",
       "      <th>treatment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>112</td>\n",
       "      <td>0.0</td>\n",
       "      <td>93.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>49</td>\n",
       "      <td>20170126</td>\n",
       "      <td>M</td>\n",
       "      <td>73000.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>240</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>113</td>\n",
       "      <td>0.0</td>\n",
       "      <td>93.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>49</td>\n",
       "      <td>20170126</td>\n",
       "      <td>M</td>\n",
       "      <td>73000.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>114</td>\n",
       "      <td>0.0</td>\n",
       "      <td>94.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>44</td>\n",
       "      <td>20180312</td>\n",
       "      <td>F</td>\n",
       "      <td>76000.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>240</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>115</td>\n",
       "      <td>0.0</td>\n",
       "      <td>94.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>44</td>\n",
       "      <td>20180312</td>\n",
       "      <td>F</td>\n",
       "      <td>76000.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>166</td>\n",
       "      <td>0.0</td>\n",
       "      <td>134.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>62</td>\n",
       "      <td>20180629</td>\n",
       "      <td>F</td>\n",
       "      <td>40000.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>240</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index  day_num  per_id  ...  offer_id_9  offer_id_10  treatment\n",
       "0    112      0.0    93.0  ...           0            0          1\n",
       "1    113      0.0    93.0  ...           0            1          0\n",
       "2    114      0.0    94.0  ...           0            0          1\n",
       "3    115      0.0    94.0  ...           0            1          0\n",
       "4    166      0.0   134.0  ...           0            0          1\n",
       "\n",
       "[5 rows x 42 columns]"
      ]
     },
     "execution_count": 39,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# encode Promotion as 0 or 1 indicator variable\n",
    "train_data['treatment'] = np.where(train_data['offer_id'] != 10, 1, 0)\n",
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5_JnjMfXFwez"
   },
   "outputs": [],
   "source": [
    "train, valid = sk.model_selection.train_test_split(train_data, test_size=0.2,random_state=42)\n",
    "\n",
    "features = ['day_num', 'per_id', 'age', 'became_member_on', 'income', 'gender_F', 'gender_M','gender_O','treatment']\n",
    "\n",
    "Y_train = train['has_profit']\n",
    "X_train = train[features]\n",
    "\n",
    "Y_valid = valid['has_profit']\n",
    "X_valid = valid[features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "fM7n85roFwe0"
   },
   "outputs": [],
   "source": [
    "# up sample with SMOTE\n",
    "sm = SMOTE(random_state=42, ratio = 1.0)\n",
    "X_train_upsamp, Y_train_upsamp = sm.fit_sample(X_train, Y_train)\n",
    "    \n",
    "X_train_upsamp = pd.DataFrame(X_train_upsamp, columns=features)\n",
    "\n",
    "Y_train_upsamp = pd.Series(Y_train_upsamp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "sy3xWY5OFwe2",
    "outputId": "ac294df8-a153-4c0d-9278-ba62b4114943"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\tvalidation_0-auc:0.890381\tvalidation_1-auc:0.766088\n",
      "Multiple eval metrics have been passed: 'validation_1-auc' will be used for early stopping.\n",
      "\n",
      "Will train until validation_1-auc hasn't improved in 30 rounds.\n",
      "[1]\tvalidation_0-auc:0.90868\tvalidation_1-auc:0.783147\n",
      "[2]\tvalidation_0-auc:0.910981\tvalidation_1-auc:0.783784\n",
      "[3]\tvalidation_0-auc:0.910802\tvalidation_1-auc:0.783867\n",
      "[4]\tvalidation_0-auc:0.930741\tvalidation_1-auc:0.800555\n",
      "[5]\tvalidation_0-auc:0.931316\tvalidation_1-auc:0.800174\n",
      "[6]\tvalidation_0-auc:0.931643\tvalidation_1-auc:0.800364\n",
      "[7]\tvalidation_0-auc:0.937656\tvalidation_1-auc:0.804337\n",
      "[8]\tvalidation_0-auc:0.937943\tvalidation_1-auc:0.805361\n",
      "[9]\tvalidation_0-auc:0.939328\tvalidation_1-auc:0.803705\n",
      "[10]\tvalidation_0-auc:0.939927\tvalidation_1-auc:0.80423\n",
      "[11]\tvalidation_0-auc:0.941199\tvalidation_1-auc:0.804503\n",
      "[12]\tvalidation_0-auc:0.942797\tvalidation_1-auc:0.805473\n",
      "[13]\tvalidation_0-auc:0.943537\tvalidation_1-auc:0.803649\n",
      "[14]\tvalidation_0-auc:0.945687\tvalidation_1-auc:0.804495\n",
      "[15]\tvalidation_0-auc:0.946301\tvalidation_1-auc:0.803859\n",
      "[16]\tvalidation_0-auc:0.947761\tvalidation_1-auc:0.805534\n",
      "[17]\tvalidation_0-auc:0.948185\tvalidation_1-auc:0.805333\n",
      "[18]\tvalidation_0-auc:0.948566\tvalidation_1-auc:0.806185\n",
      "[19]\tvalidation_0-auc:0.948586\tvalidation_1-auc:0.805654\n",
      "[20]\tvalidation_0-auc:0.949926\tvalidation_1-auc:0.807031\n",
      "[21]\tvalidation_0-auc:0.950526\tvalidation_1-auc:0.805891\n",
      "[22]\tvalidation_0-auc:0.95151\tvalidation_1-auc:0.8078\n",
      "[23]\tvalidation_0-auc:0.952973\tvalidation_1-auc:0.807487\n",
      "[24]\tvalidation_0-auc:0.954254\tvalidation_1-auc:0.807421\n",
      "[25]\tvalidation_0-auc:0.955132\tvalidation_1-auc:0.806363\n",
      "[26]\tvalidation_0-auc:0.955568\tvalidation_1-auc:0.805914\n",
      "[27]\tvalidation_0-auc:0.955882\tvalidation_1-auc:0.805187\n",
      "[28]\tvalidation_0-auc:0.956873\tvalidation_1-auc:0.80475\n",
      "[29]\tvalidation_0-auc:0.957335\tvalidation_1-auc:0.805028\n",
      "[30]\tvalidation_0-auc:0.957579\tvalidation_1-auc:0.804941\n",
      "[31]\tvalidation_0-auc:0.958856\tvalidation_1-auc:0.80686\n",
      "[32]\tvalidation_0-auc:0.959295\tvalidation_1-auc:0.807038\n",
      "[33]\tvalidation_0-auc:0.960242\tvalidation_1-auc:0.808278\n",
      "[34]\tvalidation_0-auc:0.960431\tvalidation_1-auc:0.808169\n",
      "[35]\tvalidation_0-auc:0.962006\tvalidation_1-auc:0.808616\n",
      "[36]\tvalidation_0-auc:0.962718\tvalidation_1-auc:0.810404\n",
      "[37]\tvalidation_0-auc:0.96391\tvalidation_1-auc:0.811596\n",
      "[38]\tvalidation_0-auc:0.964407\tvalidation_1-auc:0.812718\n",
      "[39]\tvalidation_0-auc:0.965396\tvalidation_1-auc:0.813275\n",
      "[40]\tvalidation_0-auc:0.965993\tvalidation_1-auc:0.814454\n",
      "[41]\tvalidation_0-auc:0.966119\tvalidation_1-auc:0.814451\n",
      "[42]\tvalidation_0-auc:0.966874\tvalidation_1-auc:0.815311\n",
      "[43]\tvalidation_0-auc:0.967308\tvalidation_1-auc:0.815855\n",
      "[44]\tvalidation_0-auc:0.967845\tvalidation_1-auc:0.815846\n",
      "[45]\tvalidation_0-auc:0.968263\tvalidation_1-auc:0.816527\n",
      "[46]\tvalidation_0-auc:0.968557\tvalidation_1-auc:0.816597\n",
      "[47]\tvalidation_0-auc:0.968805\tvalidation_1-auc:0.816751\n",
      "[48]\tvalidation_0-auc:0.969086\tvalidation_1-auc:0.817345\n",
      "[49]\tvalidation_0-auc:0.96946\tvalidation_1-auc:0.81758\n",
      "[50]\tvalidation_0-auc:0.969565\tvalidation_1-auc:0.817547\n",
      "[51]\tvalidation_0-auc:0.969674\tvalidation_1-auc:0.817264\n",
      "[52]\tvalidation_0-auc:0.970046\tvalidation_1-auc:0.817121\n",
      "[53]\tvalidation_0-auc:0.970169\tvalidation_1-auc:0.817081\n",
      "[54]\tvalidation_0-auc:0.970476\tvalidation_1-auc:0.817212\n",
      "[55]\tvalidation_0-auc:0.971097\tvalidation_1-auc:0.817177\n",
      "[56]\tvalidation_0-auc:0.971338\tvalidation_1-auc:0.817496\n",
      "[57]\tvalidation_0-auc:0.971417\tvalidation_1-auc:0.817686\n",
      "[58]\tvalidation_0-auc:0.971889\tvalidation_1-auc:0.817672\n",
      "[59]\tvalidation_0-auc:0.972169\tvalidation_1-auc:0.817076\n",
      "[60]\tvalidation_0-auc:0.972219\tvalidation_1-auc:0.817364\n",
      "[61]\tvalidation_0-auc:0.972417\tvalidation_1-auc:0.817163\n",
      "[62]\tvalidation_0-auc:0.972726\tvalidation_1-auc:0.817113\n",
      "[63]\tvalidation_0-auc:0.972859\tvalidation_1-auc:0.816835\n",
      "[64]\tvalidation_0-auc:0.972998\tvalidation_1-auc:0.817363\n",
      "[65]\tvalidation_0-auc:0.973317\tvalidation_1-auc:0.817843\n",
      "[66]\tvalidation_0-auc:0.973465\tvalidation_1-auc:0.817903\n",
      "[67]\tvalidation_0-auc:0.973635\tvalidation_1-auc:0.818129\n",
      "[68]\tvalidation_0-auc:0.973831\tvalidation_1-auc:0.818432\n",
      "[69]\tvalidation_0-auc:0.973912\tvalidation_1-auc:0.818555\n",
      "[70]\tvalidation_0-auc:0.974133\tvalidation_1-auc:0.818939\n",
      "[71]\tvalidation_0-auc:0.974339\tvalidation_1-auc:0.818739\n",
      "[72]\tvalidation_0-auc:0.974558\tvalidation_1-auc:0.818865\n",
      "[73]\tvalidation_0-auc:0.974694\tvalidation_1-auc:0.818717\n",
      "[74]\tvalidation_0-auc:0.974793\tvalidation_1-auc:0.81895\n",
      "[75]\tvalidation_0-auc:0.974932\tvalidation_1-auc:0.818954\n",
      "[76]\tvalidation_0-auc:0.975363\tvalidation_1-auc:0.819352\n",
      "[77]\tvalidation_0-auc:0.975443\tvalidation_1-auc:0.819532\n",
      "[78]\tvalidation_0-auc:0.97559\tvalidation_1-auc:0.8201\n",
      "[79]\tvalidation_0-auc:0.975696\tvalidation_1-auc:0.819851\n",
      "[80]\tvalidation_0-auc:0.975946\tvalidation_1-auc:0.820054\n",
      "[81]\tvalidation_0-auc:0.975992\tvalidation_1-auc:0.820014\n",
      "[82]\tvalidation_0-auc:0.976102\tvalidation_1-auc:0.820277\n",
      "[83]\tvalidation_0-auc:0.976223\tvalidation_1-auc:0.82015\n",
      "[84]\tvalidation_0-auc:0.976332\tvalidation_1-auc:0.819865\n",
      "[85]\tvalidation_0-auc:0.976444\tvalidation_1-auc:0.820144\n",
      "[86]\tvalidation_0-auc:0.976589\tvalidation_1-auc:0.819832\n",
      "[87]\tvalidation_0-auc:0.976659\tvalidation_1-auc:0.819707\n",
      "[88]\tvalidation_0-auc:0.976695\tvalidation_1-auc:0.819523\n",
      "[89]\tvalidation_0-auc:0.976884\tvalidation_1-auc:0.819352\n",
      "[90]\tvalidation_0-auc:0.977076\tvalidation_1-auc:0.819296\n",
      "[91]\tvalidation_0-auc:0.977181\tvalidation_1-auc:0.819417\n",
      "[92]\tvalidation_0-auc:0.977255\tvalidation_1-auc:0.819242\n",
      "[93]\tvalidation_0-auc:0.9773\tvalidation_1-auc:0.819221\n",
      "[94]\tvalidation_0-auc:0.977482\tvalidation_1-auc:0.818715\n",
      "[95]\tvalidation_0-auc:0.977665\tvalidation_1-auc:0.818452\n",
      "[96]\tvalidation_0-auc:0.978121\tvalidation_1-auc:0.818862\n",
      "[97]\tvalidation_0-auc:0.978308\tvalidation_1-auc:0.818742\n",
      "[98]\tvalidation_0-auc:0.978401\tvalidation_1-auc:0.81849\n",
      "[99]\tvalidation_0-auc:0.97861\tvalidation_1-auc:0.818604\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "              colsample_bynode=1, colsample_bytree=1, gamma=0.1,\n",
       "              learning_rate=0.1, max_delta_step=0, max_depth=7,\n",
       "              min_child_weight=5, missing=None, n_estimators=100, n_jobs=1,\n",
       "              nthread=None, objective='binary:logistic', random_state=0,\n",
       "              reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=42,\n",
       "              silent=True, subsample=1, verbosity=1)"
      ]
     },
     "execution_count": 42,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_set = [(X_train_upsamp, Y_train_upsamp), (X_valid, Y_valid)]\n",
    "model = xgb.XGBClassifier(learning_rate = 0.1,\\\n",
    "                                  max_depth = 7,\\\n",
    "                                  min_child_weight = 5,\\\n",
    "                                  objective = 'binary:logistic',\\\n",
    "                                  seed = 42,\\\n",
    "                                  gamma = 0.1,\\\n",
    "                                  silent = True)\n",
    "model.fit(X_train_upsamp, Y_train_upsamp, eval_set=eval_set,\\\n",
    "                    eval_metric=\"auc\", verbose=True, early_stopping_rounds=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "RAPq75fJFwe3",
    "outputId": "9a4d460f-f19e-4285-9916-10179e52ff43"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2370,    7],\n",
       "       [ 337,  401]])"
      ]
     },
     "execution_count": 43,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# confusion marix for thge validation set\n",
    "valid_pred = model.predict(X_valid, ntree_limit=model.best_ntree_limit)\n",
    "cm = sk.metrics.confusion_matrix(Y_valid, valid_pred)\n",
    "\n",
    "cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "BIk58VeOFwe6"
   },
   "outputs": [],
   "source": [
    "def promotion_strategy(df):\n",
    "\n",
    "    test = df\n",
    "    \n",
    "    # Fit a model with treatment = 1 for all data points\n",
    "    test['treatment'] = 1.0\n",
    "    preds_treat = model.predict_proba(test, ntree_limit=model.best_ntree_limit)\n",
    "    \n",
    "    # Fit a model with treatment = 0 for all data points\n",
    "    test['treatment'] = 0.0\n",
    "    preds_cont = model.predict_proba(test, ntree_limit=model.best_ntree_limit)\n",
    "    \n",
    "    lift = preds_treat[:,1] - preds_cont[:,1]\n",
    "    \n",
    "    promotion = []\n",
    "    \n",
    "    for prob in lift:\n",
    "        if prob > 0:\n",
    "            promotion.append('Yes')\n",
    "        else:\n",
    "            promotion.append('No')\n",
    "\n",
    "    promotion = np.array(promotion)\n",
    "    \n",
    "    return promotion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 306
    },
    "colab_type": "code",
    "id": "DCUt54KMFwe7",
    "outputId": "9eb1c2be-6aa9-4a39-efd8-c969a7531973"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Irr with this strategy is 0.3569.\n",
      "\n",
      "Nir with this strategy is 3696.50.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n",
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  # Remove the CWD from sys.path while we load stuff.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.3568782699399604, 3696.5)"
      ]
     },
     "execution_count": 45,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# find out irr and nlr on our validation set\n",
    "valid_results(promotion_strategy, valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ITTNhdD2Fwe_"
   },
   "outputs": [],
   "source": [
    "# This will test your results, and provide you back some information \n",
    "# on how well your promotion_strategy will work in practice\n",
    "\n",
    "#test_results(promotion_strategy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "0EpP-JfSFwfB"
   },
   "source": [
    "## Model 4: Four Quadrant Method\n",
    "\n",
    " It suggested designing a model to predict an individual's probability of being in any of the 4 groups: TR, CR, TN, CN.\n",
    "\n",
    "TR: Treatment and Responded. Basically received promotion and made a purchase\n",
    "CR: Control and Responded. Did not receive a promotion but made a purchase\n",
    "TN: Treatment and No Response. Received promotion but made no purchase\n",
    "CN: Control and No Response. Did not receive a promotion and made no purchase\n",
    "\n",
    "If an individual's TR probability is the highest among the four groups, it is likely that we will benefit by sending the individual a promotion to induce him or her to make a purchase."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 224
    },
    "colab_type": "code",
    "id": "rch65mTcFwfF",
    "outputId": "edb36762-4668-47b5-967c-ef61944de9ab"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>day_num</th>\n",
       "      <th>per_id</th>\n",
       "      <th>offer_id</th>\n",
       "      <th>daily_amt_spent</th>\n",
       "      <th>num_trans</th>\n",
       "      <th>amt_spent_per_trans</th>\n",
       "      <th>num_offers</th>\n",
       "      <th>cost</th>\n",
       "      <th>profit</th>\n",
       "      <th>has_profit</th>\n",
       "      <th>target</th>\n",
       "      <th>quadrant</th>\n",
       "      <th>age</th>\n",
       "      <th>became_member_on</th>\n",
       "      <th>gender</th>\n",
       "      <th>income</th>\n",
       "      <th>gender_F</th>\n",
       "      <th>gender_M</th>\n",
       "      <th>gender_O</th>\n",
       "      <th>difficulty</th>\n",
       "      <th>duration</th>\n",
       "      <th>reward</th>\n",
       "      <th>email</th>\n",
       "      <th>mobile</th>\n",
       "      <th>social</th>\n",
       "      <th>web</th>\n",
       "      <th>offer_type_bogo</th>\n",
       "      <th>offer_type_discount</th>\n",
       "      <th>offer_type_informational</th>\n",
       "      <th>offer_id_0</th>\n",
       "      <th>offer_id_1</th>\n",
       "      <th>offer_id_2</th>\n",
       "      <th>offer_id_3</th>\n",
       "      <th>offer_id_4</th>\n",
       "      <th>offer_id_5</th>\n",
       "      <th>offer_id_6</th>\n",
       "      <th>offer_id_7</th>\n",
       "      <th>offer_id_8</th>\n",
       "      <th>offer_id_9</th>\n",
       "      <th>offer_id_10</th>\n",
       "      <th>treatment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>112</td>\n",
       "      <td>0.0</td>\n",
       "      <td>93.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>49</td>\n",
       "      <td>20170126</td>\n",
       "      <td>M</td>\n",
       "      <td>73000.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>240</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>113</td>\n",
       "      <td>0.0</td>\n",
       "      <td>93.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>49</td>\n",
       "      <td>20170126</td>\n",
       "      <td>M</td>\n",
       "      <td>73000.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>114</td>\n",
       "      <td>0.0</td>\n",
       "      <td>94.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>44</td>\n",
       "      <td>20180312</td>\n",
       "      <td>F</td>\n",
       "      <td>76000.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>240</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>115</td>\n",
       "      <td>0.0</td>\n",
       "      <td>94.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>44</td>\n",
       "      <td>20180312</td>\n",
       "      <td>F</td>\n",
       "      <td>76000.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>166</td>\n",
       "      <td>0.0</td>\n",
       "      <td>134.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>62</td>\n",
       "      <td>20180629</td>\n",
       "      <td>F</td>\n",
       "      <td>40000.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>240</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index  day_num  per_id  ...  offer_id_9  offer_id_10  treatment\n",
       "0    112      0.0    93.0  ...           0            0          1\n",
       "1    113      0.0    93.0  ...           0            1          0\n",
       "2    114      0.0    94.0  ...           0            0          1\n",
       "3    115      0.0    94.0  ...           0            1          0\n",
       "4    166      0.0   134.0  ...           0            0          1\n",
       "\n",
       "[5 rows x 42 columns]"
      ]
     },
     "execution_count": 47,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target = []\n",
    "for index, row in train_data.iterrows():\n",
    "    if (row['offer_id'] != 10) & (row['has_profit'] == 1):\n",
    "        # TR group\n",
    "        target.append(0)\n",
    "    elif (['offer_id'] == 10) & (row['has_profit'] == 1):\n",
    "        # CR group\n",
    "        target.append(1)\n",
    "    elif (row['offer_id'] != 10) & (row['has_profit'] == 0):\n",
    "        # TN group\n",
    "        target.append(2)\n",
    "    else: #CN group\n",
    "        target.append(3)\n",
    "\n",
    "train_data['target'] = target\n",
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 85
    },
    "colab_type": "code",
    "id": "UIChsjJVFwfH",
    "outputId": "d5aa3b82-9bdf-46d8-e519-ef5e61845d7b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3    7745\n",
       "2    4999\n",
       "0    2830\n",
       "Name: target, dtype: int64"
      ]
     },
     "execution_count": 48,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train, valid = sk.model_selection.train_test_split(train_data, test_size=0.2,random_state=42)\n",
    "\n",
    "abc = train_data['target']\n",
    "\n",
    "abc.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7l4nQE9Q48WZ"
   },
   "outputs": [],
   "source": [
    "#features = ['V1', 'V2', 'V3', 'V4', 'V5', 'V6', 'V7']\n",
    "features = ['day_num', 'per_id', 'age', 'became_member_on', 'income', 'gender_F', 'gender_M','gender_O']\n",
    "\n",
    "Y_train = train['target']\n",
    "X_train = train[features]\n",
    "\n",
    "Y_valid = valid['target']\n",
    "X_valid = valid[features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 85
    },
    "colab_type": "code",
    "id": "fWwHMOQhFwfK",
    "outputId": "736f73d2-225a-4ae3-bb07-65fd4251deac"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3    6166\n",
       "2    4006\n",
       "0    2287\n",
       "Name: target, dtype: int64"
      ]
     },
     "execution_count": 50,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_train.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 207
    },
    "colab_type": "code",
    "id": "O6y9IfnoFwfM",
    "outputId": "812308ca-6c6a-4778-d846-bfa6970585fd"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/imblearn/utils/_validation.py:257: UserWarning: After over-sampling, the number of samples (33444) in class 0 will be larger than the number of samples in the majority class (class #3 -> 6166)\n",
      "  n_samples_majority))\n",
      "/usr/local/lib/python3.6/dist-packages/imblearn/utils/_validation.py:257: UserWarning: After over-sampling, the number of samples (33444) in class 2 will be larger than the number of samples in the majority class (class #3 -> 6166)\n",
      "  n_samples_majority))\n",
      "/usr/local/lib/python3.6/dist-packages/imblearn/utils/_validation.py:257: UserWarning: After over-sampling, the number of samples (33444) in class 3 will be larger than the number of samples in the majority class (class #3 -> 6166)\n",
      "  n_samples_majority))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "3    33444\n",
       "2    33444\n",
       "0    33444\n",
       "dtype: int64"
      ]
     },
     "execution_count": 51,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# up sample with SMOTE\n",
    "sm = SMOTE({0:33444, 2:33444, 3:33444}, random_state=42)\n",
    "X_train_upsamp, Y_train_upsamp = sm.fit_sample(X_train, Y_train)\n",
    "    \n",
    "X_train_upsamp = pd.DataFrame(X_train_upsamp, columns=features)\n",
    "\n",
    "Y_train_upsamp = pd.Series(Y_train_upsamp)\n",
    "Y_train_upsamp.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "colab_type": "code",
    "id": "wJIxk789FwfN",
    "outputId": "028a8bc8-93c4-4031-8238-0d64f46471ff"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>day_num</th>\n",
       "      <th>per_id</th>\n",
       "      <th>age</th>\n",
       "      <th>became_member_on</th>\n",
       "      <th>income</th>\n",
       "      <th>gender_F</th>\n",
       "      <th>gender_M</th>\n",
       "      <th>gender_O</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10.0</td>\n",
       "      <td>13922.0</td>\n",
       "      <td>65.0</td>\n",
       "      <td>20171226.0</td>\n",
       "      <td>63000.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>13.0</td>\n",
       "      <td>10004.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>20150824.0</td>\n",
       "      <td>84000.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>17.0</td>\n",
       "      <td>1509.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>20160215.0</td>\n",
       "      <td>100000.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>17.0</td>\n",
       "      <td>9394.0</td>\n",
       "      <td>57.0</td>\n",
       "      <td>20150927.0</td>\n",
       "      <td>87000.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>21.0</td>\n",
       "      <td>14069.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>20160715.0</td>\n",
       "      <td>53000.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   day_num   per_id   age  ...  gender_F  gender_M  gender_O\n",
       "0     10.0  13922.0  65.0  ...       1.0       0.0       0.0\n",
       "1     13.0  10004.0  50.0  ...       1.0       0.0       0.0\n",
       "2     17.0   1509.0  60.0  ...       1.0       0.0       0.0\n",
       "3     17.0   9394.0  57.0  ...       1.0       0.0       0.0\n",
       "4     21.0  14069.0  50.0  ...       1.0       0.0       0.0\n",
       "\n",
       "[5 rows x 8 columns]"
      ]
     },
     "execution_count": 52,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_upsamp.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "0u82ALCWFwfP",
    "outputId": "65eb5046-c974-4fb4-e875-b31013e3bf49"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\tvalidation_0-mlogloss:1.08849\tvalidation_1-mlogloss:1.09031\n",
      "Multiple eval metrics have been passed: 'validation_1-mlogloss' will be used for early stopping.\n",
      "\n",
      "Will train until validation_1-mlogloss hasn't improved in 30 rounds.\n",
      "[1]\tvalidation_0-mlogloss:1.07938\tvalidation_1-mlogloss:1.0828\n",
      "[2]\tvalidation_0-mlogloss:1.07186\tvalidation_1-mlogloss:1.07573\n",
      "[3]\tvalidation_0-mlogloss:1.0651\tvalidation_1-mlogloss:1.07004\n",
      "[4]\tvalidation_0-mlogloss:1.0595\tvalidation_1-mlogloss:1.06499\n",
      "[5]\tvalidation_0-mlogloss:1.0539\tvalidation_1-mlogloss:1.06134\n",
      "[6]\tvalidation_0-mlogloss:1.04927\tvalidation_1-mlogloss:1.05778\n",
      "[7]\tvalidation_0-mlogloss:1.04467\tvalidation_1-mlogloss:1.05436\n",
      "[8]\tvalidation_0-mlogloss:1.04076\tvalidation_1-mlogloss:1.05151\n",
      "[9]\tvalidation_0-mlogloss:1.03715\tvalidation_1-mlogloss:1.04923\n",
      "[10]\tvalidation_0-mlogloss:1.03352\tvalidation_1-mlogloss:1.04483\n",
      "[11]\tvalidation_0-mlogloss:1.03007\tvalidation_1-mlogloss:1.04291\n",
      "[12]\tvalidation_0-mlogloss:1.02683\tvalidation_1-mlogloss:1.04007\n",
      "[13]\tvalidation_0-mlogloss:1.02325\tvalidation_1-mlogloss:1.03624\n",
      "[14]\tvalidation_0-mlogloss:1.02017\tvalidation_1-mlogloss:1.03488\n",
      "[15]\tvalidation_0-mlogloss:1.01706\tvalidation_1-mlogloss:1.03123\n",
      "[16]\tvalidation_0-mlogloss:1.01376\tvalidation_1-mlogloss:1.03038\n",
      "[17]\tvalidation_0-mlogloss:1.01055\tvalidation_1-mlogloss:1.02705\n",
      "[18]\tvalidation_0-mlogloss:1.00781\tvalidation_1-mlogloss:1.02589\n",
      "[19]\tvalidation_0-mlogloss:1.00473\tvalidation_1-mlogloss:1.0231\n",
      "[20]\tvalidation_0-mlogloss:1.00222\tvalidation_1-mlogloss:1.02193\n",
      "[21]\tvalidation_0-mlogloss:0.999338\tvalidation_1-mlogloss:1.02084\n",
      "[22]\tvalidation_0-mlogloss:0.997004\tvalidation_1-mlogloss:1.01931\n",
      "[23]\tvalidation_0-mlogloss:0.994414\tvalidation_1-mlogloss:1.0183\n",
      "[24]\tvalidation_0-mlogloss:0.992326\tvalidation_1-mlogloss:1.01663\n",
      "[25]\tvalidation_0-mlogloss:0.990085\tvalidation_1-mlogloss:1.01606\n",
      "[26]\tvalidation_0-mlogloss:0.986792\tvalidation_1-mlogloss:1.0121\n",
      "[27]\tvalidation_0-mlogloss:0.984917\tvalidation_1-mlogloss:1.01099\n",
      "[28]\tvalidation_0-mlogloss:0.982686\tvalidation_1-mlogloss:1.00942\n",
      "[29]\tvalidation_0-mlogloss:0.980224\tvalidation_1-mlogloss:1.00912\n",
      "[30]\tvalidation_0-mlogloss:0.977526\tvalidation_1-mlogloss:1.00522\n",
      "[31]\tvalidation_0-mlogloss:0.975076\tvalidation_1-mlogloss:1.00463\n",
      "[32]\tvalidation_0-mlogloss:0.973551\tvalidation_1-mlogloss:1.00408\n",
      "[33]\tvalidation_0-mlogloss:0.97068\tvalidation_1-mlogloss:1.00124\n",
      "[34]\tvalidation_0-mlogloss:0.969167\tvalidation_1-mlogloss:1.00101\n",
      "[35]\tvalidation_0-mlogloss:0.967413\tvalidation_1-mlogloss:1.00144\n",
      "[36]\tvalidation_0-mlogloss:0.964868\tvalidation_1-mlogloss:0.999251\n",
      "[37]\tvalidation_0-mlogloss:0.963408\tvalidation_1-mlogloss:0.999491\n",
      "[38]\tvalidation_0-mlogloss:0.961159\tvalidation_1-mlogloss:0.996713\n",
      "[39]\tvalidation_0-mlogloss:0.959582\tvalidation_1-mlogloss:0.997035\n",
      "[40]\tvalidation_0-mlogloss:0.957909\tvalidation_1-mlogloss:0.995365\n",
      "[41]\tvalidation_0-mlogloss:0.956029\tvalidation_1-mlogloss:0.993943\n",
      "[42]\tvalidation_0-mlogloss:0.954822\tvalidation_1-mlogloss:0.993325\n",
      "[43]\tvalidation_0-mlogloss:0.953958\tvalidation_1-mlogloss:0.993382\n",
      "[44]\tvalidation_0-mlogloss:0.953165\tvalidation_1-mlogloss:0.993345\n",
      "[45]\tvalidation_0-mlogloss:0.95193\tvalidation_1-mlogloss:0.992391\n",
      "[46]\tvalidation_0-mlogloss:0.950274\tvalidation_1-mlogloss:0.992574\n",
      "[47]\tvalidation_0-mlogloss:0.948632\tvalidation_1-mlogloss:0.992995\n",
      "[48]\tvalidation_0-mlogloss:0.947857\tvalidation_1-mlogloss:0.992784\n",
      "[49]\tvalidation_0-mlogloss:0.946506\tvalidation_1-mlogloss:0.992998\n",
      "[50]\tvalidation_0-mlogloss:0.944992\tvalidation_1-mlogloss:0.99399\n",
      "[51]\tvalidation_0-mlogloss:0.943429\tvalidation_1-mlogloss:0.993254\n",
      "[52]\tvalidation_0-mlogloss:0.942523\tvalidation_1-mlogloss:0.993484\n",
      "[53]\tvalidation_0-mlogloss:0.941189\tvalidation_1-mlogloss:0.992935\n",
      "[54]\tvalidation_0-mlogloss:0.940127\tvalidation_1-mlogloss:0.993548\n",
      "[55]\tvalidation_0-mlogloss:0.938539\tvalidation_1-mlogloss:0.992976\n",
      "[56]\tvalidation_0-mlogloss:0.937228\tvalidation_1-mlogloss:0.993603\n",
      "[57]\tvalidation_0-mlogloss:0.936346\tvalidation_1-mlogloss:0.994051\n",
      "[58]\tvalidation_0-mlogloss:0.935514\tvalidation_1-mlogloss:0.994438\n",
      "[59]\tvalidation_0-mlogloss:0.934263\tvalidation_1-mlogloss:0.993866\n",
      "[60]\tvalidation_0-mlogloss:0.933738\tvalidation_1-mlogloss:0.993968\n",
      "[61]\tvalidation_0-mlogloss:0.931623\tvalidation_1-mlogloss:0.993619\n",
      "[62]\tvalidation_0-mlogloss:0.930681\tvalidation_1-mlogloss:0.994443\n",
      "[63]\tvalidation_0-mlogloss:0.929614\tvalidation_1-mlogloss:0.995017\n",
      "[64]\tvalidation_0-mlogloss:0.926853\tvalidation_1-mlogloss:0.995969\n",
      "[65]\tvalidation_0-mlogloss:0.925108\tvalidation_1-mlogloss:0.995648\n",
      "[66]\tvalidation_0-mlogloss:0.924096\tvalidation_1-mlogloss:0.995946\n",
      "[67]\tvalidation_0-mlogloss:0.922944\tvalidation_1-mlogloss:0.996473\n",
      "[68]\tvalidation_0-mlogloss:0.92138\tvalidation_1-mlogloss:0.995755\n",
      "[69]\tvalidation_0-mlogloss:0.919902\tvalidation_1-mlogloss:0.996581\n",
      "[70]\tvalidation_0-mlogloss:0.91922\tvalidation_1-mlogloss:0.997132\n",
      "[71]\tvalidation_0-mlogloss:0.917893\tvalidation_1-mlogloss:0.997334\n",
      "[72]\tvalidation_0-mlogloss:0.9165\tvalidation_1-mlogloss:0.997069\n",
      "[73]\tvalidation_0-mlogloss:0.91568\tvalidation_1-mlogloss:0.997716\n",
      "[74]\tvalidation_0-mlogloss:0.915154\tvalidation_1-mlogloss:0.998162\n",
      "[75]\tvalidation_0-mlogloss:0.914173\tvalidation_1-mlogloss:0.998664\n",
      "Stopping. Best iteration:\n",
      "[45]\tvalidation_0-mlogloss:0.95193\tvalidation_1-mlogloss:0.992391\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "              colsample_bynode=1, colsample_bytree=1, gamma=0.1,\n",
       "              learning_rate=0.1, max_delta_step=0, max_depth=7,\n",
       "              min_child_weight=5, missing=None, n_estimators=100, n_jobs=1,\n",
       "              nthread=None, num_class=4, objective='multi:softprob',\n",
       "              random_state=0, reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
       "              seed=42, silent=True, subsample=1, verbosity=1)"
      ]
     },
     "execution_count": 53,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_set = [(X_train_upsamp, Y_train_upsamp), (X_valid, Y_valid)]\n",
    "model = xgb.XGBClassifier(learning_rate = 0.1,\\\n",
    "                          num_class=4,\\\n",
    "                                  max_depth = 7,\\\n",
    "                                  min_child_weight = 5,\\\n",
    "                                  objective = 'multi:softmax',\\\n",
    "                                  seed = 42,\\\n",
    "                                  gamma = 0.1,\\\n",
    "                                  silent = True)\n",
    "model.fit(X_train_upsamp, Y_train_upsamp, eval_set=eval_set,\\\n",
    "                    eval_metric=\"mlogloss\", verbose=True, early_stopping_rounds=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "colab_type": "code",
    "id": "8TgrfqeWFwfQ",
    "outputId": "355d4110-7e00-4aba-8f3a-bf4e6e47a186"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[241,  86, 216],\n",
       "       [  2, 539, 452],\n",
       "       [324, 882, 373]])"
      ]
     },
     "execution_count": 54,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# confusion marix for thge validation set\n",
    "# Note:\n",
    "# TR: treatment and respond group (received promotion and made purchase)\n",
    "# CR: control and respond group (did not receive promotion but made purchase)\n",
    "# TN: treatment and no respond group (received promotion but did not made purchase)\n",
    "# CR: control and no respond group (did not receive promotion and made no purchase)\n",
    "valid_pred = model.predict(X_valid, ntree_limit=model.best_ntree_limit)\n",
    "cm = sk.metrics.confusion_matrix(Y_valid, valid_pred)\n",
    "\n",
    "cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "uCt_uM3zFwfZ"
   },
   "outputs": [],
   "source": [
    "def promotion_strategy(df):\n",
    "\n",
    "    test = df\n",
    "    \n",
    "    pred = model.predict(test, ntree_limit=model.best_ntree_limit)\n",
    "    \n",
    "    promotion = []\n",
    "    \n",
    "    for pred in pred:\n",
    "        if pred == 0:\n",
    "            promotion.append('Yes')\n",
    "        else:\n",
    "            promotion.append('No')\n",
    "    \n",
    "    promotion = np.array(promotion)\n",
    "    \n",
    "    return promotion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 102
    },
    "colab_type": "code",
    "id": "dVse9ADOFwfb",
    "outputId": "66b6a7b2-1a4a-4fdc-d702-fddee87493af"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Irr with this strategy is 0.9146.\n",
      "\n",
      "Nir with this strategy is 2123.55.\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.9146090534979424, 2123.55)"
      ]
     },
     "execution_count": 56,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# find out irr and nlr on our validation set\n",
    "valid_results(promotion_strategy, valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "MkEUqPKYFwfe"
   },
   "outputs": [],
   "source": [
    "# This will test your results, and provide you back some information \n",
    "# on how well your promotion_strategy will work in practice\n",
    "\n",
    "#test_results(promotion_strategy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "PoK1Pk5hSr61"
   },
   "source": [
    "Thus, model 3 gives the best strategy and will be used for evaluating our individual offers to predict the best irr and nir for the Test_case customers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "2NVggUHoTTbK"
   },
   "source": [
    "This approach is first suggested by Victor Lo in the [presentation](https://www.slideshare.net/odsc/victor-lomachinelearningpresentation)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "JvJ3OSskTddt"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "hrERVVhBFweE",
    "FdRYQ6ijFwev",
    "0EpP-JfSFwfB"
   ],
   "name": "Starbucks_Uplift_Models_Comparison.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
